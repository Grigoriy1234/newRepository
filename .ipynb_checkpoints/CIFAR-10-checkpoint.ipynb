{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Split_dataset(file,percent):\n",
    "    name=[i for i in range(len(file[0]))]\n",
    "    test_data=pd.DataFrame(columns=name)\n",
    "    train_data=pd.DataFrame(columns=name)\n",
    "    df = pd.DataFrame(file)\n",
    "    print(len(df))\n",
    "    for i in range(len(df)):                   \n",
    "        if np.random.rand()<percent:\n",
    "            test_data.loc[len(test_data)]=list(df.loc[i])\n",
    "        else:\n",
    "            train_data.loc[len(train_data)]=list(df.loc[i])\n",
    "        if i%300==0:\n",
    "            print(round((i/len(df))*100),'%',end=\"|\")\n",
    "    print('100 %')\n",
    "\n",
    "    return test_data,train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Similarity(data_instances1,data_instances2,l=4):#Euclidean metric\n",
    "    return np.sqrt(sum([(data_instances1[i]-data_instances2[i])**2 for i in range(l)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kNeighbors(train_data,data_instances,k,radius=False):\n",
    "    Neighbors = [[Similarity(data_instances,train_data.loc[i].tolist()),train_data.loc[i].tolist()]for i in range(len(train_data))]\n",
    "    Neighbors=sorted(Neighbors,key=lambda x:x[0])\n",
    "    \n",
    "    if radius:\n",
    "        l=0\n",
    "        for i in Neighbors:\n",
    "            #print('%%',i[0],' ',k,'%%')\n",
    "            if i[0]<k:\n",
    "                l+=1\n",
    "            else:\n",
    "                if l==0:\n",
    "                    l=1\n",
    "                break\n",
    "        return Neighbors[:l]\n",
    "    else:\n",
    "        return Neighbors[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Response(Neighbors):\n",
    "    Iris_type = {}\n",
    "    for j in Neighbors:\n",
    "        if j[1][-1] not in Iris_type:\n",
    "            Iris_type[j[1][-1]]=1\n",
    "        else:\n",
    "            Iris_type[j[1][-1]]+=1\n",
    "    prediction=[0,'']\n",
    "    for j in Iris_type.keys():\n",
    "        if Iris_type[j]>prediction[0]:\n",
    "            prediction[0]=Iris_type[j]\n",
    "            prediction[1]=j\n",
    "    return prediction[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(train_data,test_data,k_Neighbors,radius=False):\n",
    "    success=0\n",
    "    for i in range(len(test_data)):\n",
    "        test=test_data.loc[i].tolist()\n",
    "        print('\\n\\nПроверка: ',test[-5:])\n",
    "        Neighbors = get_kNeighbors(train_data,test,k_Neighbors,radius=radius)\n",
    "        print('\\nБлижайшние данные к проверяемым:\\n',[i[1][-1] for i in Neighbors])\n",
    "        prediction = get_Response(Neighbors)\n",
    "        print('Предсказание:\\n',prediction)\n",
    "        if test[-1]==prediction:\n",
    "            success+=1\n",
    "            print('\\nПредсказание верное\\n\\n\\n')\n",
    "        print(\"Выполнено:\",i/len(test_data),'%', 'Успешно:',success)\n",
    "    return (success/len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(path,files):\n",
    "    C_10=[0,0]\n",
    "    for i in range(len(files)):\n",
    "        print('Loading:',path+files[i])\n",
    "        tmp_file=unpickle(path+files[i])  \n",
    "        if i==0:\n",
    "            C_10[1]=tmp_file[b'labels']\n",
    "            C_10[0]=tmp_file[b'data'].tolist()\n",
    "        else:\n",
    "            C_10[1]+=tmp_file[b'labels']\n",
    "            C_10[0]+=tmp_file[b'data'].tolist()\n",
    "#         print(len(C_10[0])) \n",
    "#         print(len(C_10[1]))  \n",
    "#         print(len(C_10),'\\n')\n",
    "    \n",
    "    for i in range(len(C_10[0])):\n",
    "        C_10[0][i]+=[C_10[1][i]]\n",
    "        if i%10000==0:\n",
    "            print(round((i/len(C_10[0]))*100),'%')\n",
    "    print('100 %')\n",
    "    return C_10[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: cifar-10-python/cifar-10-batches-py/data_batch_1\n",
      "Loading: cifar-10-python/cifar-10-batches-py/data_batch_2\n",
      "Loading: cifar-10-python/cifar-10-batches-py/data_batch_3\n",
      "Loading: cifar-10-python/cifar-10-batches-py/data_batch_4\n",
      "Loading: cifar-10-python/cifar-10-batches-py/data_batch_5\n",
      "0 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Loading: cifar-10-python/cifar-10-batches-py/test_batch\n",
      "0 %\n",
      "100 %\n"
     ]
    }
   ],
   "source": [
    "path='cifar-10-python/cifar-10-batches-py/'\n",
    "files_train=['data_batch_1','data_batch_2','data_batch_3','data_batch_4','data_batch_5']#\n",
    "files_test=['test_batch']\n",
    "C_10_train=get_data(path,files_train)\n",
    "C_10_test=get_data(path,files_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3073\n"
     ]
    }
   ],
   "source": [
    "print(len(C_10_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# border = 10000\n",
    "# test_data_size=2000\n",
    "# percent=test_data_size/float(border)\n",
    "test_data=pd.DataFrame(C_10_test[:2500])\n",
    "train_data=pd.DataFrame(C_10_train)\n",
    "# test_data,train_data=Split_dataset(C_10_test,1)\n",
    "# test_data,train_data=Split_dataset(C_10_train,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(test_data))#\n",
    "print(len(train_data))#\n",
    "print(len(train_data)+len(test_data))#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_Neighbors=20\n",
    "rk_Neighbors=15\n",
    "get_accuracy(train_data,test_data,rk_Neighbors,radius=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
